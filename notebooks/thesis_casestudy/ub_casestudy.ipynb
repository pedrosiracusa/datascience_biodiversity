{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UB Herbarium Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dsetPath = '/home/pedro/datasets/ub_herbarium/occurrence.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['recordedBy', 'scientificName', 'family', 'genus', 'species','taxonRank', \n",
    "        'stateProvince', 'locality', 'municipality', 'occurrenceRemarks',\n",
    "        'eventDate', 'identifiedBy']\n",
    "occs = pd.read_table(dsetPath, delimiter='\\t', usecols=cols, low_memory=False)\n",
    "occs.dropna(subset=['recordedBy','scientificName'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 185301 entries, 0 to 185310\n",
      "Data columns (total 12 columns):\n",
      "recordedBy           185301 non-null object\n",
      "occurrenceRemarks    140768 non-null object\n",
      "eventDate            181254 non-null object\n",
      "stateProvince        174285 non-null object\n",
      "municipality         135291 non-null object\n",
      "locality             163029 non-null object\n",
      "identifiedBy         148600 non-null object\n",
      "scientificName       185301 non-null object\n",
      "family               182987 non-null object\n",
      "genus                176755 non-null object\n",
      "taxonRank            185301 non-null object\n",
      "species              152360 non-null object\n",
      "dtypes: object(12)\n",
      "memory usage: 18.4+ MB\n"
     ]
    }
   ],
   "source": [
    "occs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordedBy</th>\n",
       "      <th>occurrenceRemarks</th>\n",
       "      <th>eventDate</th>\n",
       "      <th>stateProvince</th>\n",
       "      <th>municipality</th>\n",
       "      <th>locality</th>\n",
       "      <th>identifiedBy</th>\n",
       "      <th>scientificName</th>\n",
       "      <th>family</th>\n",
       "      <th>genus</th>\n",
       "      <th>taxonRank</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Irwin, HS</td>\n",
       "      <td>Ascending subshrub 0,3m. Fruit gray-green; Cer...</td>\n",
       "      <td>1972-01-16T01:00Z</td>\n",
       "      <td>Goiás</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Serra dos Pireneus, ca. 20km E of Pirenópolis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Annona monticola Mart.</td>\n",
       "      <td>Annonaceae</td>\n",
       "      <td>Annona</td>\n",
       "      <td>SPECIES</td>\n",
       "      <td>Annona monticola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ratter, JA; et al.</td>\n",
       "      <td>Coppice branches sprouting from the stump of a...</td>\n",
       "      <td>1976-06-30T01:00Z</td>\n",
       "      <td>Minas Gerais</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Near Pandeiros, ca. 30.0 km W of Januária</td>\n",
       "      <td>Flora do Brasil</td>\n",
       "      <td>Myracrodruon urundeuva Allem.</td>\n",
       "      <td>Anacardiaceae</td>\n",
       "      <td>Myracrodruon</td>\n",
       "      <td>SPECIES</td>\n",
       "      <td>Myracrodruon urundeuva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heringer, EP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1954-06-05T01:00Z</td>\n",
       "      <td>Minas Gerais</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fazenda do Rasgão. Terreno de cultura</td>\n",
       "      <td>Flora do Brasil</td>\n",
       "      <td>Myracrodruon urundeuva Allem.</td>\n",
       "      <td>Anacardiaceae</td>\n",
       "      <td>Myracrodruon</td>\n",
       "      <td>SPECIES</td>\n",
       "      <td>Myracrodruon urundeuva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coelho, JP</td>\n",
       "      <td>Pouco frequente, sem folhas nesse período; Árv...</td>\n",
       "      <td>1964-10-15T01:00Z</td>\n",
       "      <td>Minas Gerais</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IPEACO- Sete lagoas</td>\n",
       "      <td>Flora do Brasil</td>\n",
       "      <td>Myracrodruon urundeuva Allem.</td>\n",
       "      <td>Anacardiaceae</td>\n",
       "      <td>Myracrodruon</td>\n",
       "      <td>SPECIES</td>\n",
       "      <td>Myracrodruon urundeuva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eiten, G; Eiten, LT</td>\n",
       "      <td>Tree 5.0 m. tall, 11.0 cm d.b.h. With young fr...</td>\n",
       "      <td>1963-08-17T01:00Z</td>\n",
       "      <td>Maranhão</td>\n",
       "      <td>Loreto</td>\n",
       "      <td>Ilha de Balsas region, between the Balsas and ...</td>\n",
       "      <td>Flora do Brasil</td>\n",
       "      <td>Myracrodruon urundeuva Allem.</td>\n",
       "      <td>Anacardiaceae</td>\n",
       "      <td>Myracrodruon</td>\n",
       "      <td>SPECIES</td>\n",
       "      <td>Myracrodruon urundeuva</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            recordedBy                                  occurrenceRemarks  \\\n",
       "0            Irwin, HS  Ascending subshrub 0,3m. Fruit gray-green; Cer...   \n",
       "1   Ratter, JA; et al.  Coppice branches sprouting from the stump of a...   \n",
       "2         Heringer, EP                                                NaN   \n",
       "3           Coelho, JP  Pouco frequente, sem folhas nesse período; Árv...   \n",
       "4  Eiten, G; Eiten, LT  Tree 5.0 m. tall, 11.0 cm d.b.h. With young fr...   \n",
       "\n",
       "           eventDate stateProvince municipality  \\\n",
       "0  1972-01-16T01:00Z         Goiás          NaN   \n",
       "1  1976-06-30T01:00Z  Minas Gerais          NaN   \n",
       "2  1954-06-05T01:00Z  Minas Gerais          NaN   \n",
       "3  1964-10-15T01:00Z  Minas Gerais          NaN   \n",
       "4  1963-08-17T01:00Z      Maranhão       Loreto   \n",
       "\n",
       "                                            locality     identifiedBy  \\\n",
       "0      Serra dos Pireneus, ca. 20km E of Pirenópolis              NaN   \n",
       "1          Near Pandeiros, ca. 30.0 km W of Januária  Flora do Brasil   \n",
       "2              Fazenda do Rasgão. Terreno de cultura  Flora do Brasil   \n",
       "3                                IPEACO- Sete lagoas  Flora do Brasil   \n",
       "4  Ilha de Balsas region, between the Balsas and ...  Flora do Brasil   \n",
       "\n",
       "                  scientificName         family         genus taxonRank  \\\n",
       "0         Annona monticola Mart.     Annonaceae        Annona   SPECIES   \n",
       "1  Myracrodruon urundeuva Allem.  Anacardiaceae  Myracrodruon   SPECIES   \n",
       "2  Myracrodruon urundeuva Allem.  Anacardiaceae  Myracrodruon   SPECIES   \n",
       "3  Myracrodruon urundeuva Allem.  Anacardiaceae  Myracrodruon   SPECIES   \n",
       "4  Myracrodruon urundeuva Allem.  Anacardiaceae  Myracrodruon   SPECIES   \n",
       "\n",
       "                  species  \n",
       "0        Annona monticola  \n",
       "1  Myracrodruon urundeuva  \n",
       "2  Myracrodruon urundeuva  \n",
       "3  Myracrodruon urundeuva  \n",
       "4  Myracrodruon urundeuva  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185301"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Counts</th>\n",
       "      <th>Perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SPECIES</th>\n",
       "      <td>140763</td>\n",
       "      <td>0.759645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GENUS</th>\n",
       "      <td>24397</td>\n",
       "      <td>0.131661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VARIETY</th>\n",
       "      <td>8935</td>\n",
       "      <td>0.048219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAMILY</th>\n",
       "      <td>6223</td>\n",
       "      <td>0.033583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KINGDOM</th>\n",
       "      <td>2008</td>\n",
       "      <td>0.010836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUBSPECIES</th>\n",
       "      <td>1681</td>\n",
       "      <td>0.009072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FORM</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.005397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PHYLUM</th>\n",
       "      <td>294</td>\n",
       "      <td>0.001587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Counts      Perc\n",
       "SPECIES     140763  0.759645\n",
       "GENUS        24397  0.131661\n",
       "VARIETY       8935  0.048219\n",
       "FAMILY        6223  0.033583\n",
       "KINGDOM       2008  0.010836\n",
       "SUBSPECIES    1681  0.009072\n",
       "FORM          1000  0.005397\n",
       "PHYLUM         294  0.001587"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = pd.DataFrame(occs['taxonRank'].value_counts())\n",
    "counts.columns = ['Counts']\n",
    "counts['Perc'] = counts['Counts']/counts['Counts'].sum()\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning collector data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/caryocar/caryocar/cleaning.py:536: UserWarning: A names map was created without a normalization function!\n",
      "  warn(\"A names map was created without a normalization function!\")\n"
     ]
    }
   ],
   "source": [
    "from caryocar.cleaning import read_NamesMap_fromJson, NamesAtomizer, namesFromString\n",
    "\n",
    "# read a names map\n",
    "nm = read_NamesMap_fromJson('../ub_names_map_2.json')\n",
    "\n",
    "# atomizing names\n",
    "atomizingOp = lambda x: namesFromString(x)\n",
    "na = NamesAtomizer(atomizingOp)\n",
    "\n",
    "occs['recordedBy_atomized'] = na.atomize(occs['recordedBy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the names index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caryocar.cleaning import getNamesIndexes\n",
    "\n",
    "ni = getNamesIndexes(occs,'recordedBy_atomized',nm.getMap())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caryocar.models import CoworkingNetwork, SpeciesCollectorsNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total number of collectors in the dataset: 7245'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "namesList = list(set(nm.getMap().values()))\n",
    "\n",
    "\"Total number of collectors in the dataset: \"+str(len(namesList)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collectors co-working Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3c26c2bec34b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcwn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCoworkingNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamesSets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moccs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'recordedBy_atomized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamesMap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/pedro/caryocar/caryocar/models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, cliques, namesMap, **attr)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# insert nodes and set count attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mnodes_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclique\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcliques\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclique\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "cwn = CoworkingNetwork(namesSets=occs['recordedBy_atomized'], weighted=True, namesMap=nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering some nodes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodesToRemove = ['etal','']\n",
    "cwn.remove_nodes_from(nodesToRemove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nodes degrees\n",
    "nx.set_node_attributes(cwn, 'degree', cwn.degree())\n",
    "\n",
    "# nodes weighted degrees\n",
    "nx.set_node_attributes(cwn, 'degree_weighted', cwn.degree(weight='weight'))\n",
    "\n",
    "# total number of records for each collector (includes non-collaborative records)\n",
    "count_totalRecords = lambda name,index: len(index[name]) \n",
    "nx.set_node_attributes(cwn, 'tot_records', dict( (n, count_totalRecords(n,ni) ) for n in cwn.nodes() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove self-loops\n",
    "\n",
    "self_loops = [ (u,v) for u,v in cwn.edges() if u==v ] \n",
    "cwn.remove_edges_from(self_loops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.write_gexf(cwn, './graphs/ub_graph_cwn.gexf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Species-collectors Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll only use records with the taxonomic resolution of species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "occs_sp = occs[occs['species'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scn = SpeciesCollectorsNetwork(species=occs_sp['species'], \n",
    "                               collectorsNames=occs_sp['recordedBy_atomized'],\n",
    "                              weighted=True, namesMap=nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering some nodes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodesToRemove = ['etal','']\n",
    "scn.remove_nodes_from(nodesToRemove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nodes degrees\n",
    "nx.set_node_attributes(scn, 'degree', scn.degree())\n",
    "\n",
    "# nodes weighted degrees\n",
    "nx.set_node_attributes(scn, 'degree_weighted', scn.degree(weight='weight'))\n",
    "\n",
    "# set species families\n",
    "sp_families = occs_sp[['species','family']].drop_duplicates()\n",
    "sp_families_dict = dict(zip(sp_families['species'],sp_families['family']))\n",
    "nx.set_node_attributes(scn, 'family', sp_families_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.write_gexf(scn, './ub_graph_scn.gexf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregating species by family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def aggregateByTaxLevel(network, level):\n",
    "    spNodes = network.getSpeciesNodes(data=True)\n",
    "    taxonMap = dict( (sp,d[level]) for sp,d in spNodes )\n",
    "    taxGroupsNames = list(set(taxonMap.values()))\n",
    "\n",
    "    edgesList = [ (taxonMap[u],v,d) for u,v,d in network.edges((n for n,d in spNodes), data=True) ]\n",
    "    edges = Counter( (u,v) for u,v,d in edgesList for i in range(d['weight']) )\n",
    "\n",
    "    net_aggr = SpeciesCollectorsNetwork()\n",
    "    net_aggr.add_nodes_from(network.getCollectorsNodes(),bipartite=0)\n",
    "    net_aggr.add_nodes_from(taxGroupsNames, bipartite=1)\n",
    "    net_aggr.add_edges_from( (u,v,{'weight':w}) for (u,v),w in edges.items() )\n",
    "    \n",
    "    return net_aggr\n",
    "\n",
    "G = aggregateByTaxLevel(scn,'family')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.set_node_attributes(G,'degree',G.degree())\n",
    "nx.set_node_attributes(G,'degree_weighted',G.degree(weight='weight'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing collectors species bags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting a collector's species bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can, for example, retrieve the species bag for `proenca,ceb`. When we unpack the tuple, the first element is the list of the species names, and the second is a 1-row sparse matrix where her species bag is stored in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i,m = scn.getSpeciesBag('proenca,ceb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first ten (species,count) tuples from the speciesBag\n",
    "list( zip( i, np.array(m.todense()).flatten() ) )[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Species Bags Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the similarity of collectors from their species bag using the Cosine Similarity metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scipy\n",
    "\n",
    "def calculateSimilarity( G, col1=None, col2=None ):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "    If neither col1 and col2 are informed, a tuple ( colsList, csr_sparse_similarityMatrix )\n",
    "    If only col1 is informed, a tuple ( colsList, similarityVector )\n",
    "    If col1 and col2 are informed, a tuple ( [col1,col2], similarity )\n",
    "    \"\"\"\n",
    "    colList, spList, m = G._speciesBag_matrix\n",
    "    \n",
    "    if col1 is not None:\n",
    "        if col2 is not None:\n",
    "            sim = cosine_similarity( scn.getSpeciesBag(col1)[1], scn.getSpeciesBag(col2)[1] )[0][0] \n",
    "            return ([col1,col2], sim)\n",
    "        else:\n",
    "            simVector = cosine_similarity( scn.getSpeciesBag(col1)[1], m )\n",
    "            return ( colList, scipy.sparse.csr_matrix(simVector) )\n",
    "        \n",
    "    else:\n",
    "        return( colList, scipy.sparse.csr_matrix(cosine_similarity(m)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to retrieve the full species bag matrix, we simply call this function without collectors names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i,m = calculateSimilarity(scn)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively we can get a similarity vector for a particular collector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i,m = calculateSimilarity(scn,'munhoz,cbr')\n",
    "m.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the top-10 collectors most similar to munhoz,cbr \n",
    "sorted(list(zip(i,np.array(m.todense()).flatten())),key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the similarity score for a pair of collectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols,score = calculateSimilarity(scn,'munhoz,cbr','proenca,ceb')\n",
    "\"Similarity of the species bags of {} and {}: {}\".format(*cols,score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define a filtering function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For a **sparse matrix**, I'll iterate through non-zero elements and apply a threshold function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i,m = calculateSimilarity(scn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m[0:10,164:174].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresh = 0.1\n",
    "m.data = np.where(m.data>=thresh,m.data,0)\n",
    "m.eliminate_zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m[0:10,164:174].todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* And the same for similarity vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i,m = calculateSimilarity(scn, 'munhoz,cbr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.todense()[0,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresh = 0.01\n",
    "m.data = np.where(m.data>=thresh,m.data,0)\n",
    "m.eliminate_zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.todense()[0,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(m.indices)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(m.data)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_row=20\n",
    "i_col=0\n",
    "n_rows=10\n",
    "n_cols=10\n",
    "'''\n",
    "for i in range(i_row,i_row+n_rows):\n",
    "    for j in range(i_col,i_col+n_cols):\n",
    "        print(i,j)\n",
    "'''\n",
    "\n",
    "m[i_row:i_row+n_rows,i_col:i_col+n_cols].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresh = lambda x: x if x>0.5 else 0\n",
    "thresh = np.vectorize(thresh)\n",
    "m.data = thresh(m.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in m.todense()[:10,:10].shape:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.todense()[:10,:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = lambda x: x if x>0.5 else 0\n",
    "thresh = np.vectorize(thresh)\n",
    "m.data = thresh(m.data)\n",
    "\n",
    "m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limit = lambda x: x if x>0.5 else 0\n",
    "limit = np.vectorize(limit)\n",
    "\n",
    "m_l = limit(m.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(m_l.shape[0]):\n",
    "    for j in range(m_l.shape[1]):\n",
    "        print(m[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i,m = calculateSimilarity(scn)\n",
    "\n",
    "limit(m)\n",
    "#sorted(list(zip(i,m_limit)),key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m=cosine_similarity(G._speciesBag_matrix[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col1='moura,co'\n",
    "col2='siracusa,p'\n",
    "cosine_similarity(scn.getSpeciesBag(col1),scn.getSpeciesBag(col2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m=cosine_similarity(scn._speciesBag_matrix[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresh = lambda x: x if x>0.6 else 0\n",
    "thresh=np.vectorize(thresh)\n",
    "\n",
    "m_t = thresh(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy as scp\n",
    "\n",
    "m_sparse = scp.sparse.csr_matrix(m_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_sparse.setdiag(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = nx.from_scipy_sparse_matrix(m_sparse)\n",
    "\n",
    "nMap = dict( (i,n) for i,n in enumerate(scn._speciesBag_matrix[0]) )\n",
    "g = nx.relabel_nodes(g,nMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_weighted_dict = dict( (n,d['degree_weighted']) for n,d in scn.getCollectorsNodes(data=True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.set_node_attributes(g,'k_weighted',k_weighted_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.write_gexf(g,'graph.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_proj = nx.bipartite.projection.collaboration_weighted_projected_graph(G,G.getSpeciesNodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_proj.edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_proj.edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.write_gexf(G_proj,'./ub_graph_scn_family.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_edges_from([('a','b',{'w':1}),('a','c',{'w':2})])\n",
    "\n",
    "G.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spNodes = [ (n,d) for n,d in scn.nodes(data=True) if d['bipartite']==1 ]\n",
    "spDict = dict( (sp,d['family']) for sp,d in spNodes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edges = [ (spDict[u],v,d) for u,v,d in scn.edges([n for n,d in spNodes], data=True) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[ (u,[v for i in range(d['weight'])]) for u,v,d in edges ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edgesDict = dict()\n",
    "\n",
    "for u,v,d in edges:\n",
    "    currWeight = d['weight']\n",
    "    try:\n",
    "        edgesDict[(u,v)]['weight'] += currWeight\n",
    "        \n",
    "    except:\n",
    "        edgesDict[(u,v)] = {}\n",
    "        edgesDict[(u,v)]['weight'] = currWeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert( sum( data['weight'] for k,data in edgesDict.items() ) == sum( data['weight'] for k,v,data in edges ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.Graph( (u,v,d) for (u,v),d in edgesDict.items() ).nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(zip(occs['species'],occs['recordedBy_atomized']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spNodes = [ (n,d) for n,d in scn.nodes(data=True) if d['bipartite']==1 ]\n",
    "\n",
    "# First group nodes\n",
    "\n",
    "groups = [ (data['family'],n) for n,data in spNodes ]\n",
    "groupsDict = dict()\n",
    "for k,v in groups:\n",
    "    groupsDict[k] = [v] + groupsDict.get( k,[] )\n",
    "    \n",
    "groupsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# then merge nodes attributes\n",
    "newNodes = dict()\n",
    "interest_attrs = ['degree', 'degree_weighted']\n",
    "\n",
    "for g in groupsDict.keys():\n",
    "    group_attrs = [ scn.node[n] for n in groupsDict[g] ]\n",
    "\n",
    "    newNodes[g] = dict( (attr,sum(i[attr] for i in group_attrs)) for attr in interest_attrs )\n",
    "    \n",
    "newNodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# then merge edges\n",
    "\n",
    "newEdges = list()\n",
    "\n",
    "for g in groupsDict.keys():\n",
    "\n",
    "    neighbors = [ (u,d) for sp in groupsDict[g] for u,d in scn[sp].items() ]\n",
    "\n",
    "    neighbors_dict =dict()\n",
    "\n",
    "    for n,data in neighbors:\n",
    "        neighbors_dict[n] = neighbors_dict.get(n,{'weight':0})\n",
    "        neighbors_dict[n]['weight'] += data['weight']\n",
    "        \n",
    "    newEdges += [ (g,v,data) for v,data in neighbors_dict.items() ]\n",
    "\n",
    "newEdges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aggregateByFamily( network ):\n",
    "    \n",
    "    spNodes = [ (n,d) for n,d in scn.nodes(data=True) if d['bipartite']==1 ] # species nodes\n",
    "    interest_attrs = ['degree', 'degree_weighted'] # node attrs to merge\n",
    "\n",
    "    # First group nodes\n",
    "    groups = [ (data['family'],n) for n,data in spNodes ]\n",
    "    groupsDict = dict()\n",
    "    for k,v in groups:\n",
    "        groupsDict[k] = [v] + groupsDict.get( k,[] )\n",
    "    \n",
    "    groupsNames = groupsDict.keys()\n",
    "    \n",
    "    # then merge nodes attributes\n",
    "    getNodeAttributes = lambda n: network.node[n]\n",
    "\n",
    "    newNodes = dict()\n",
    "    for g in groupsNames:\n",
    "        group_attrs = [ getNodeAttributes(sp) for sp in groupsDict[g] ]\n",
    "        newNodes[g] = dict( (attr,sum(i[attr] for i in group_attrs)) for attr in interest_attrs )\n",
    "        \n",
    "\n",
    "    # then merge edges\n",
    "\n",
    "    newEdges = list()\n",
    "\n",
    "    for g in groupsDict.keys():\n",
    "\n",
    "        neighbors = [ (u,d) for sp in groupsDict[g] for u,d in scn[sp].items() ]\n",
    "\n",
    "        neighbors_dict =dict()\n",
    "        for n,data in neighbors:\n",
    "            neighbors_dict[n] = neighbors_dict.get(n,{'weight':0})\n",
    "            neighbors_dict[n]['weight'] += data['weight']\n",
    "\n",
    "        newEdges += [ (g,v,data) for v,data in neighbors_dict.items() ]\n",
    "\n",
    "    \n",
    "    res = nx.Graph()\n",
    "    res.add_edges_from(newEdges)\n",
    "    res.add_nodes_from(newNodes)\n",
    "    \n",
    "    for n,d in newNodes.items():\n",
    "        res.node[n].update(**d)\n",
    "        \n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = aggregateByFamily(scn)\n",
    "g.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(newNodes.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(zip(*newNodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newNodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = aggregateByFamily(scn)\n",
    "\n",
    "g.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newNodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spNodes = ( (n,d) for n,d in scn.nodes(data=True) if d['bipartite']==1 )\n",
    "\n",
    "sum(  v['degree_weighted'] for k,v in spNodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spNodes = ( (n,d) for n,d in scn.nodes(data=True) if d['bipartite']==1 )\n",
    "\n",
    "sum(  v['degree_weighted'] for k,v in fDict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {'a':1,'b':2}\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scn_aggregate=deepcopy(scn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes = [ (d['family'],d) for n,d in scn.nodes(data=True) if d['bipartite']==1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scn.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "occs[['scientificName','family']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn = SpeciesCollectorsNetwork(species=occs_sporg['family'],\n",
    "                               collectorsNames=occs_sporg['recordedBy_atomized'],\n",
    "                               weighted=True, namesMap=nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodesToRemove = ['etal','']\n",
    "fcn.remove_nodes_from(nodesToRemove)\n",
    "\n",
    "# nodes degrees\n",
    "nx.set_node_attributes(fcn, 'degree', fcn.degree())\n",
    "\n",
    "# nodes weighted degrees\n",
    "nx.set_node_attributes(fcn, 'degree_weighted', fcn.degree(weight='weight'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.write_gexf(fcn, './ub_graph_fcn.gexf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Who are the most prolific collectors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rc_dict = {\n",
    "    'axes.grid':True,\n",
    "    'grid.color':'.9'\n",
    "}\n",
    "\n",
    "sns.set_context('talk')\n",
    "sns.set_style('ticks', rc_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f,(ax1,ax2) = plt.subplots(2,1,sharex=True,figsize=(8,12))\n",
    "\n",
    "# ax1\n",
    "d = [ data['tot_records'] for name,data in cwn.nodes(data=True) ]\n",
    "y,x = np.histogram(d,bins=range(1,20141,1),density=True)\n",
    "y = np.cumsum(y)\n",
    "\n",
    "y_norm,x_norm = np.histogram(np.random.normal(loc=10000, scale=3000, size=20140),\n",
    "             bins=range(1,20141,1), density=True)\n",
    "y_norm = np.cumsum(y_norm)\n",
    "\n",
    "ax1.plot(x[:-1],y)\n",
    "ax1.plot(x_norm[:-1],y_norm,ls='dashed')\n",
    "ax1.semilogx()\n",
    "\n",
    "plt.xlabel(\"# Records\")\n",
    "ax1.set_ylabel(\"Cumulative percentual of collectors\")\n",
    "\n",
    "# ax2\n",
    "\n",
    "from collections import Counter\n",
    "numCols = len(d)\n",
    "x,y = list(zip(*[ (nrecs,c) for nrecs,c in Counter(d).items() ]))\n",
    "\n",
    "ax2.scatter(x,y,facecolor='none',edgecolors='k',marker='o',s=80, linewidth=0.2)\n",
    "ax2.loglog()\n",
    "\n",
    "ax2.set_ylabel(\"# Collectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "occs['num_collabs'] = occs['recordedBy_atomized'].apply(lambda l: len(l)-1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_collabs = [ (n,occs['num_collabs'].loc[ni[n]].mean()) for n in cwn.nodes() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[ (u,v) for u,v in num_collabs if u=='proenca,ceb' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist( [m for n,m in num_collabs],bins=range(12))\n",
    "plt.xlabel(\"Average # of Collaborators\")\n",
    "plt.ylabel(\"# Collectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot([m for n,m in num_collabs],bins=range(12),kde_kws={'bw':0.5})\n",
    "plt.xlabel(\"Average # of Collaborators\")\n",
    "plt.ylabel(\"Percentage of Collectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure. Distribution of the average number of collaborators for each collector.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "y,x = np.histogram(occs['num_collabs']+1,bins=range(1,11))\n",
    "\n",
    "func_powerlaw = lambda x,a,b0,b1: a*pow(x,b0)*np.exp(-x/b1) # power law w/ exponential cutoff\n",
    "\n",
    "pars_powerlaw,covs_powerlaw = curve_fit(func_powerlaw,x[:-1],y, maxfev=100000)\n",
    "\n",
    "\n",
    "plt.scatter(x[:-1],y,facecolor='none',edgecolor='k',linewidth=1,s=400)\n",
    "plt.plot(x,func_powerlaw(x,*pars_powerlaw), '--')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.ylim(0.5e0,2e5)\n",
    "plt.xlabel(\"# Collectors\")\n",
    "plt.ylabel(\"# Records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure. Number of records by size of the collectors team. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Should the number of species collected follow a power law?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "collectors = nx.bipartite.sets(scn)[0]\n",
    "\n",
    "degree_dist = Counter(scn.degree(collectors).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "degree_dist = Counter( d['degree_weighted'] for n,d in scn.nodes(data=True) if d['bipartite']==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "degrees,cnts = zip(*degree_dist.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(degrees,cnts,facecolor='none',edgecolor='k')\n",
    "\n",
    "plt.scatter(X,func(X,*params),marker='+',edgecolor='k', linewidth=0.5)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "func = lambda x,l,t,a: (l**(1-a))/(t*(1-a))*x**(-a)*np.exp(-l*x) \n",
    "\n",
    "X = degrees\n",
    "y = cnts\n",
    "\n",
    "params,covs = curve_fit(func,X,y)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "func(X,*params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(X,func(X,*params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sig1 = [0,2,0,0,3,41,54,0,3,13,4,5,0,0,1,0,0,1,0,3]\n",
    "sig2 = [32,0,2,0,3,0,56,0,13,0,0,42,0,21,0,0,1,0,4,9]\n",
    "\n",
    "sig1 = [0,0,2,1,0]\n",
    "sig2 = [0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.linalg.norm(sig1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(sig1),len(sig2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.dot(sig1,sig2)/(np.linalg.norm(sig1)*np.linalg.norm(sig2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
