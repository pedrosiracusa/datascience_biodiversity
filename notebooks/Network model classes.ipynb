{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Co-working Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "class CoworkingNetwork(networkx.Graph):\n",
    "    \"\"\"\n",
    "    Class for coworking networks. Extends networkx Graph class.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    namesSets : iterable\n",
    "        An iterable of iterables containing names used to compose cliques \n",
    "        in the network.\n",
    "\n",
    "    weighted : bool\n",
    "        If set to True the resulting network will have weighted edges. Default False.\n",
    "        \n",
    "    namesMap : NamesMap\n",
    "        A NamesMap object for normalizing nodes names.\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> namesSets = [ ['a','b','c'], ['d','e'], ['a','c'] ]\n",
    "    >>> CoworkingNetwork( namesSets, weighted=True).edges(data=True)\n",
    "    [('b', 'a', {'weight': 1}),\n",
    "     ('b', 'c', {'weight': 1}),\n",
    "     ('a', 'c', {'weight': 2}),\n",
    "     ('e', 'd', {'weight': 1})]\n",
    "    \n",
    "    >>> CoworkingNetwork( namesSets ).edges(data=True)\n",
    "    [('b', 'a', {}), \n",
    "     ('b', 'c', {}), \n",
    "     ('a', 'c', {}), \n",
    "     ('e', 'd', {})]\n",
    "    \"\"\"\n",
    "    def __init__(self, data=None, namesSets=None, weighted=False, namesMap=None, **attr):\n",
    "       \n",
    "        if namesSets is not None:\n",
    "            if namesMap:\n",
    "                nmap = namesMap.getMap()\n",
    "                namesSets = [ [ nmap[n] for n in nset ] for nset in namesSets ]\n",
    "\n",
    "            cliques = map( lambda n: itertools.combinations(n,r=2), namesSets )\n",
    "            data = [ e for edges in cliques for e in edges ]\n",
    "\n",
    "        super().__init__(data=data,**attr)\n",
    "\n",
    "        if weighted:\n",
    "            edges = data\n",
    "            edges_weights = Counter(edges)\n",
    "\n",
    "            for (u,v),w in edges_weights.items():\n",
    "                try:\n",
    "                    self[u][v]['weight'] += w\n",
    "                except:\n",
    "                    self[u][v]['weight'] = w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsetpath = \"/home/pedro/datasets/ub_herbarium/occurrence.txt\"\n",
    "occs = pd.read_table(dsetpath, usecols=['recordedBy','scientificName']).dropna()\n",
    "occs['scientificName'] = occs['scientificName'].astype(str)\n",
    "occs['recordedBy'] = occs['recordedBy'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/datascience_biodiversity/notebooks/modules/cleaning/names.py:536: UserWarning: A names map was created without a normalization function!\n",
      "  warn(\"A names map was created without a normalization function!\")\n"
     ]
    }
   ],
   "source": [
    "from modules.cleaning.names import read_NamesMap_fromJson, NamesAtomizer\n",
    "from modules.cleaning.names import namesFromString\n",
    "nm = read_NamesMap_fromJson('./ub_names_map_2.json')\n",
    "\n",
    "atomizingOp = lambda x: namesFromString(x)\n",
    "na = NamesAtomizer(atomizingOp)\n",
    "occs['recordedBy_atomized'] = na.atomize(occs['recordedBy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = CoworkingNetwork(namesSets=occs['recordedBy_atomized'],weighted=True, namesMap=nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['salu,g', 'menezes,lc', 'lima,ha', 'schmidt,a']"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "list(nx.connected_component_subgraphs(G))[5].nodes()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
